{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Trick to work with current code in repo\n",
    "This add the location of the fc files in this repo to the system paths so it can be imported as normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "lib_path = os.path.abspath(os.path.join('..'))\n",
    "sys.path.append(lib_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xlrd\n",
    "import collections\n",
    "def import_rows(workbook_name,\n",
    "                worksheet_name):\n",
    "    '''\n",
    "    Access an excel doument and imports data from a specific spreadsheet.\n",
    "    Returns a list of dictionaries, which contain key value pairs of the data\n",
    "    *  The spreadsheet should contain a header row with the names of each key.\n",
    "    *  Each subsequent row then contains the values contained in a single dictionary.\n",
    "    *  Header row keys are parsed from A1 until a column without a entry is reached.\n",
    "    *  Dictionaries are parsed until a row is reached which as no values for any key.\n",
    "        This means that empty values for a key are acceptable for a row\n",
    "    '''\n",
    "    rows_data = []\n",
    "    # Load workbook and sheet\n",
    "    workbook = xlrd.open_workbook(workbook_name)\n",
    "    if 'cells' not in workbook.sheet_names():\n",
    "        raise IOError('No sheet named cells! Name the worksheet used to import data cells please')\n",
    "    worksheet = workbook.sheet_by_name(worksheet_name)\n",
    "    for r in range(worksheet.nrows):\n",
    "        row = worksheet.row(r)\n",
    "        #Import headers\n",
    "        if r==0:\n",
    "            headers = [header.value for header in row]\n",
    "        #Import row\n",
    "        else:\n",
    "            row_data = collections.OrderedDict()\n",
    "            for c, cell in enumerate(row):\n",
    "                value = cell.value\n",
    "                if value != None and isinstance(value, basestring) and len(value) > 0 and value[0] == '=':\n",
    "                    raise ImportError(\"Error: Ran into an excel formula, use plain text only. (\"+str(r)+', '+str(c)+')')\n",
    "                if headers[c]!= '':\n",
    "                    row_data[headers[c]] = value                \n",
    "            #If row was empty breakt the for loop\n",
    "            if sum([v != None for k, v in row_data.iteritems()]) == 0:\n",
    "                print [v is None for k, v in row_data.iteritems()]\n",
    "                break;\n",
    "            else:\n",
    "                rows_data.append(row_data)\n",
    "    return rows_data\n",
    "\n",
    "import xlwt\n",
    "def export_workbook(workbook_name, worksheet_data):\n",
    "    '''\n",
    "    Writes a list of lists to a excel file\n",
    "    Overwrite cells but not worksheets\n",
    "    The first dimension is associated with the column, the second\n",
    "    dimension is associated with the row\n",
    "    '''\n",
    "    #Create Workbook\n",
    "    workbook = xlwt.Workbook()\n",
    "    \n",
    "    for name, data in worksheet_data.iteritems():\n",
    "        sheet = workbook.add_sheet(name)\n",
    "        for c, column_vector in enumerate(data):\n",
    "            for r, value in enumerate(column_vector):\n",
    "                sheet.write(r, c, value)    \n",
    "    try:\n",
    "        workbook.save(workbook_name)\n",
    "    except IOError:\n",
    "        raise IOError(\"Excel document must be closed! Please save and close it and run this script again!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import fc.plot\n",
    "import gc\n",
    "def gate_plot(ungated_points, gated_points, contour, title='', filename=None):\n",
    "    '''\n",
    "    Plots both the FSC SSC scatterplot with gate, and the overlay of channel one gated and ungated histograms\n",
    "    Used to confirm automated gating was approriate for each sample\n",
    "    '''\n",
    "    fig = plt.figure(figsize=(12,9))\n",
    "    density_ax = fig.add_subplot(2,1,1)\n",
    "    \n",
    "    fc.plot.density2d(ungated_points, gate = contour, sigma=2.5, ax = density_ax, colorbar=False,xlabel='FSC-H',ylabel='SSC-H')\n",
    "    density_ax.set_aspect('auto')\n",
    "    plt.title(title)\n",
    "    \n",
    "    flour_ax = fig.add_subplot(2,1,2)\n",
    "    fc.plot.hist1d(ungated_points[:,2],ax = flour_ax,edge_color=(0.5, 0.85, 0.3), face_color=(0.8, 0.95, 0.7))\n",
    "    fc.plot.hist1d(gated_points[:,2],ax = flour_ax, edge_color=(0.2, 0.7, 0), face_color=(0.6, 0.9, 0.4),xlabel='FL1-H')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if filename != None:\n",
    "        filename = plot_gated_folder + '/gated_%03d.png'%(i+1)\n",
    "        plt.savefig(filename, bbox_inches='tight')\n",
    "    \n",
    "    plt.close()\n",
    "    fig.clf()\n",
    "    gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "def generate_stats(samples):\n",
    "    '''\n",
    "    Takes a set of samples, generate stats for them\n",
    "    \n",
    "    More stats can be added in the future\n",
    "    '''\n",
    "    def function_specifier(fn, channel=0, attribute=''):\n",
    "        def fn_wrapper(data):\n",
    "            return fn(getattr(sample, attribute, sample), channel) #pass any arguments to fn()\n",
    "        return fn_wrapper\n",
    "\n",
    "    def counts(data, channel):\n",
    "        return data[:,channel].size\n",
    "    \n",
    "    def mean(data, channel):\n",
    "        return numpy.mean(data[:,channel])\n",
    "\n",
    "    def mode(data, channel):\n",
    "        return numpy.argmax(numpy.bincount(data[:,channel].astype('int32')))\n",
    "\n",
    "    def std(data, channel):\n",
    "        return numpy.std(data[:,channel])\n",
    "\n",
    "    def CV(data, channel):\n",
    "        return numpy.std(data[:,channel])/numpy.mean(data[:,channel])\n",
    "    \n",
    "    def median(data, channel):\n",
    "        return numpy.median(data[:,channel])\n",
    "\n",
    "    def iqr(data, channel):\n",
    "        q75, q25 = numpy.percentile(data[:,channel], [75 ,25])\n",
    "        return q75 - q25\n",
    "    \n",
    "    def RCV(data, channel):\n",
    "        q75, q25 = numpy.percentile(data[:,channel], [75 ,25])\n",
    "        return numpy.median(data[:,channel])/(q75 - q25)\n",
    "    \n",
    "    stat_functions = []\n",
    "\n",
    "    data_attribute = 'data_transformed'\n",
    "    \n",
    "    stat_functions.append(('Ungated Counts',function_specifier(counts)))\n",
    "    stat_functions.append(('Gated Counts',function_specifier(counts, attribute = data_attribute)))\n",
    "    \n",
    "    for channel in ['FL1-H', 'FL2-H', 'FL3-H']:\n",
    "        stat_functions.append((channel+' Mean',function_specifier(mean, channel, data_attribute)))\n",
    "        stat_functions.append((channel+' Mode',function_specifier(mode, channel, data_attribute)))\n",
    "        stat_functions.append((channel+' Std',function_specifier(std, channel, data_attribute)))\n",
    "        stat_functions.append((channel+' CV',function_specifier(CV, channel, data_attribute)))\n",
    "        stat_functions.append((channel+' Median',function_specifier(median, channel, data_attribute)))\n",
    "        stat_functions.append((channel+' IQR',function_specifier(iqr, channel, data_attribute)))\n",
    "        stat_functions.append((channel+' RCV',function_specifier(RCV, channel, data_attribute)))\n",
    "\n",
    "    output = []\n",
    "    \n",
    "    for header in samples[0].metadata.keys():\n",
    "        output.append([header])\n",
    "    for name, stat_function in stat_functions:\n",
    "        output.append([name])\n",
    "        \n",
    "    for sample in samples:\n",
    "        i = 0\n",
    "        # Add meta data to output array\n",
    "        for header, value in sample.metadata.iteritems():\n",
    "            if value == None:\n",
    "                value = ''\n",
    "            output[i].append(value)\n",
    "            i+=1\n",
    "        for name, stat_function in stat_functions:\n",
    "            value = stat_function(sample.data_transformed)\n",
    "            output[i].append(value)\n",
    "            i+=1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import fc.gate\n",
    "def auto_gate(sample, gate_fraction=.2, sigma=10):\n",
    "    '''\n",
    "    * Gates out first and last channel of all 5 channels\n",
    "    * Gates out first 250 events and last 100 events of run\n",
    "    * Performs a density gate on remaining data\n",
    "    * Transforms data to an exponential form\n",
    "    '''\n",
    "    \n",
    "    gate_fraction = float(sample.metadata['Gate Fraction']) if 'Gate Fraction' in sample.metadata and sample.metadata['Gate Fraction'] != '' else gate_fraction\n",
    "    sigma = float(sample.metadata['Sigma']) if 'Sigma' in sample.metadata and sample.metadata['Sigma'] != '' else sigma\n",
    "    \n",
    "    high_low_gate = fc.gate.high_low(sample, high=(2**10)-1, low=0)\n",
    "    start_stop_gate = fc.gate.start_stop(sample, num_start=250, num_stop=100)\n",
    "    data_coarse = sample[high_low_gate*start_stop_gate]\n",
    "    \n",
    "    density2d_gate, density2d_contour = fc.gate.density2d(data_coarse,gate_fraction = gate_fraction,sigma = sigma)\n",
    "    data_fine = data_coarse[density2d_gate]\n",
    "    \n",
    "    return data_fine, data_coarse, density2d_contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import fc.transform\n",
    "def auto_transform(data, metadata, cached_beads):\n",
    "    \n",
    "    beads_file_path = metadata['Beads File Path'] if 'Beads File Path' in metadata and metadata['Beads File Path'] != '' else None\n",
    "    beads_peaks = [float(x) for x in metadata['Beads Peaks'].split(',')] if 'Beads Peaks' in metadata and metadata['Beads Peaks'] != '' else None\n",
    "    \n",
    "    #If they just include one parameter\n",
    "    if beads_file_path != None and beads_peaks == None or beads_file_path == None and beads_peaks != None:\n",
    "        raise ImportError('You must provide both the Beads File Path and the Beads Peaks (see: '+metadata['File Path']+')')\n",
    "    \n",
    "    #If beads are not provided just exponentiate\n",
    "    if beads_file_path == None and beads_peaks == None:\n",
    "        return fc.transform.exponentiate(data)\n",
    "    \n",
    "    #If file/peaks have already been cached use them, otherwise compute new ones\n",
    "    if beads_file_path in cached_beads.keys():\n",
    "        mefl_transform = cached_beads[beads_file_path]\n",
    "    else:\n",
    "        bead_data = fc.io.TaborLabFCSData(beads_file_path)\n",
    "        # common gating/trimming\n",
    "        ss_m = fc.gate.start_stop(bead_data[:,[0,1]])\n",
    "        hl_m = fc.gate.high_low(bead_data[:,[0,1]])\n",
    "        cm = ss_m & hl_m\n",
    "        trimmed_data = bead_data[cm,:]\n",
    "\n",
    "        # density gate\n",
    "        dm,cntr = fc.gate.density2d(data=trimmed_data, gate_fraction=0.4, sigma=10)\n",
    "        gated_data = trimmed_data[dm]\n",
    "\n",
    "        # mef\n",
    "        mefl = [None, 792.,2079.,6588.,16471.,47497.,137049.,271647.]\n",
    "        peaks_mef = numpy.array(mefl)\n",
    "        o = fc.transform.get_mef_standard_curve(gated_data, peaks_mef, \n",
    "           cluster_channels = ['FL1-H', 'FL2-H', 'FL3-H'],\n",
    "           mef_channels = 'FL1-H', verbose = False,);\n",
    "        mefl_transform = o[0]\n",
    "        beads[beads_file_path] = mefl_transform\n",
    "    return mefl_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files...\n",
      "Generating gate for file: 1,  2,  3,  4,  5,  6,  7,  \n",
      "Generating plots for file: 1,  2,  3,  4,  5,  6,  7,  \n",
      "Generating stats...\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "import fc.gate, fc.transform, fc.io, os\n",
    "from Tkinter import Tk\n",
    "from tkFileDialog import askopenfilename\n",
    "\n",
    "\n",
    "\n",
    "# Import bead metadata\n",
    "# Load bead data\n",
    "# Analysis bead data\n",
    "# Graph bead data\n",
    "# Import cell metadata\n",
    "\n",
    "#Tk().withdraw() # we don't want a full GUI, so keep the root window from appearing\n",
    "#import_path = askopenfilename() # show an \"Open\" dialog box and return the path to the selected file\n",
    "import_path = \"input_form.xlsx\"\n",
    "directory = os.path.dirname(os.path.realpath(import_path))\n",
    "print \"Loading files...\"\n",
    "# Load Files\n",
    "samples = []\n",
    "for row in import_rows(import_path,\"cells\"):\n",
    "    sample = fc.io.TaborLabFCSData(row['File Path'])\n",
    "    sample.metadata = row\n",
    "    samples.append(sample)\n",
    "    \n",
    "# Generate Gates\n",
    "print \"Generating gate for file:\",\n",
    "beads_cache = {}\n",
    "for i, sample in enumerate(samples):\n",
    "    print str(i+1)+', ',\n",
    "    sample.data_fine, sample.data_coarse, sample.density2d_contour = auto_gate(sample)\n",
    "    transformed_data = auto_transform(sample, sample.metadata, beads_cache)\n",
    "    sample.data_transformed = transformed_data\n",
    "print ''\n",
    "    \n",
    "# Plot graphs of gating\n",
    "print \"Generating plots for file:\",\n",
    "plot_gated_folder = os.path.join(directory,'plot_gated')\n",
    "if not os.path.exists(plot_gated_folder):\n",
    "    os.makedirs(plot_gated_folder)\n",
    "for i, sample in enumerate(samples): \n",
    "    print str(i+1)+', ',\n",
    "    gate_plot(sample.data_coarse, sample.data_fine, sample.density2d_contour, title = sample.metadata['File Path'], filename = os.path.join(plot_gated_folder,'gated_%03d.png'%(i+1)))\n",
    "print ''\n",
    "\n",
    "# Generate stats\n",
    "print 'Generating stats...'\n",
    "output = generate_stats(samples)\n",
    "export_workbook(os.path.join(directory,'mefled_data.xls'),{'stats2':output})\n",
    "print 'All done!'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
