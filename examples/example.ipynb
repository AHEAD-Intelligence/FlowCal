{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Trick to work with current code in repo\n",
    "This add the location of the fc files in this repo to the system paths so it can be imported as normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "lib_path = os.path.abspath(os.path.join('..'))\n",
    "sys.path.append(lib_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xlrd\n",
    "import collections\n",
    "def import_rows(workbook_name,\n",
    "                worksheet_name):\n",
    "    '''\n",
    "    Access an excel doument and imports data from a specific spreadsheet.\n",
    "    Returns a list of dictionaries, which contain key value pairs of the data\n",
    "    *  The spreadsheet should contain a header row with the names of each key.\n",
    "    *  Each subsequent row then contains the values contained in a single dictionary.\n",
    "    *  Header row keys are parsed from A1 until a column without a entry is reached.\n",
    "    *  Dictionaries are parsed until a row is reached which as no values for any key.\n",
    "        This means that empty values for a key are acceptable for a row\n",
    "    '''\n",
    "    rows_data = []\n",
    "    # Load workbook and sheet\n",
    "    workbook = xlrd.open_workbook(workbook_name)\n",
    "    if 'cells' not in workbook.sheet_names():\n",
    "        raise IOError('No sheet named cells! Name the worksheet used to import data cells please')\n",
    "    worksheet = workbook.sheet_by_name(worksheet_name)\n",
    "    for r in range(worksheet.nrows):\n",
    "        row = worksheet.row(r)\n",
    "        #Import headers\n",
    "        if r==0:\n",
    "            headers = [header.value for header in row]\n",
    "        #Import row\n",
    "        else:\n",
    "            row_data = collections.OrderedDict()\n",
    "            for c, cell in enumerate(row):\n",
    "                value = cell.value\n",
    "                if value != None and isinstance(value, basestring) and len(value) > 0 and value[0] == '=':\n",
    "                    raise ImportError(\"Error: Ran into an excel formula, use plain text only. (\"+str(r)+', '+str(c)+')')\n",
    "                if headers[c]!= '':\n",
    "                    row_data[headers[c]] = value                \n",
    "            #If row was empty breakt the for loop\n",
    "            if sum([v != None for k, v in row_data.iteritems()]) == 0:\n",
    "                print [v is None for k, v in row_data.iteritems()]\n",
    "                break;\n",
    "            else:\n",
    "                rows_data.append(row_data)\n",
    "    return rows_data\n",
    "\n",
    "import xlwt\n",
    "def export_workbook(workbook_name, worksheet_data):\n",
    "    '''\n",
    "    Writes a list of lists to a excel file\n",
    "    Overwrite cells but not worksheets\n",
    "    The first dimension is associated with the column, the second\n",
    "    dimension is associated with the row\n",
    "    '''\n",
    "    #Create Workbook\n",
    "    workbook = xlwt.Workbook()\n",
    "    \n",
    "    for name, data in worksheet_data.iteritems():\n",
    "        sheet = workbook.add_sheet(name)\n",
    "        for c, column_vector in enumerate(data):\n",
    "            for r, value in enumerate(column_vector):\n",
    "                sheet.write(r, c, value)    \n",
    "    try:\n",
    "        workbook.save(workbook_name)\n",
    "    except IOError:\n",
    "        raise IOError(\"Excel document must be closed! Please save and close it and run this script again!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import fc.plot\n",
    "import gc\n",
    "def gate_plot(ungated_points, gated_points, contour, title='', filename=None):\n",
    "    '''\n",
    "    Plots both the FSC SSC scatterplot with gate, and the overlay of channel one gated and ungated histograms\n",
    "    Used to confirm automated gating was approriate for each sample\n",
    "    '''\n",
    "    fig = plt.figure(figsize=(12,9))\n",
    "    density_ax = fig.add_subplot(2,1,1)\n",
    "    \n",
    "    fc.plot.density2d(ungated_points, gate = contour, sigma=2.5, ax = density_ax, colorbar=False,xlabel='FSC-H',ylabel='SSC-H')\n",
    "    density_ax.set_aspect('auto')\n",
    "    plt.title(title)\n",
    "    \n",
    "    flour_ax = fig.add_subplot(2,1,2)\n",
    "    fc.plot.hist1d(ungated_points[:,2],ax = flour_ax,edge_color=(0.5, 0.85, 0.3), face_color=(0.8, 0.95, 0.7))\n",
    "    fc.plot.hist1d(gated_points[:,2],ax = flour_ax, edge_color=(0.2, 0.7, 0), face_color=(0.6, 0.9, 0.4),xlabel='FL1-H')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if filename != None:\n",
    "        filename = plot_gated_folder + '/gated_%03d.png'%(i+1)\n",
    "        plt.savefig(filename, bbox_inches='tight')\n",
    "    \n",
    "    plt.close()\n",
    "    fig.clf()\n",
    "    gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "def generate_stats(samples):\n",
    "    '''\n",
    "    Takes a set of samples, generate stats for them\n",
    "    \n",
    "    More stats can be added in the future\n",
    "    '''\n",
    "    def function_specifier(fn, channel=0, attribute=''):\n",
    "        def fn_wrapper(data):\n",
    "            return fn(getattr(sample, attribute, sample), channel) #pass any arguments to fn()\n",
    "        return fn_wrapper\n",
    "\n",
    "    def counts(data, channel):\n",
    "        return data[:,channel].size\n",
    "    \n",
    "    def mean(data, channel):\n",
    "        return numpy.mean(data[:,channel])\n",
    "\n",
    "    def mode(data, channel):\n",
    "        return numpy.argmax(numpy.bincount(data[:,channel].astype('int32')))\n",
    "\n",
    "    def std(data, channel):\n",
    "        return numpy.std(data[:,channel])\n",
    "\n",
    "    def CV(data, channel):\n",
    "        return numpy.std(data[:,channel])/numpy.mean(data[:,channel])\n",
    "    \n",
    "    def median(data, channel):\n",
    "        return numpy.median(data[:,channel])\n",
    "\n",
    "    def iqr(data, channel):\n",
    "        q75, q25 = numpy.percentile(data[:,channel], [75 ,25])\n",
    "        return q75 - q25\n",
    "    \n",
    "    def RCV(data, channel):\n",
    "        q75, q25 = numpy.percentile(data[:,channel], [75 ,25])\n",
    "        return numpy.median(data[:,channel])/(q75 - q25)\n",
    "    \n",
    "    stat_functions = []\n",
    "\n",
    "    data_attribute = 'data_transformed'\n",
    "    \n",
    "    stat_functions.append(('Ungated Counts',function_specifier(counts)))\n",
    "    stat_functions.append(('Gated Counts',function_specifier(counts, attribute = data_attribute)))\n",
    "    \n",
    "    for channel in ['FL1-H', 'FL2-H', 'FL3-H']:\n",
    "        stat_functions.append((channel+' Mean',function_specifier(mean, channel, data_attribute)))\n",
    "        stat_functions.append((channel+' Mode',function_specifier(mode, channel, data_attribute)))\n",
    "        stat_functions.append((channel+' Std',function_specifier(std, channel, data_attribute)))\n",
    "        stat_functions.append((channel+' CV',function_specifier(CV, channel, data_attribute)))\n",
    "        stat_functions.append((channel+' Median',function_specifier(median, channel, data_attribute)))\n",
    "        stat_functions.append((channel+' IQR',function_specifier(iqr, channel, data_attribute)))\n",
    "        stat_functions.append((channel+' RCV',function_specifier(RCV, channel, data_attribute)))\n",
    "\n",
    "    output = []\n",
    "    \n",
    "    for header in samples[0].metadata.keys():\n",
    "        output.append([header])\n",
    "    for name, stat_function in stat_functions:\n",
    "        output.append([name])\n",
    "        \n",
    "    for sample in samples:\n",
    "        i = 0\n",
    "        # Add meta data to output array\n",
    "        for header, value in sample.metadata.iteritems():\n",
    "            if value == None:\n",
    "                value = ''\n",
    "            output[i].append(value)\n",
    "            i+=1\n",
    "        for name, stat_function in stat_functions:\n",
    "            value = stat_function(sample.data_transformed)\n",
    "            output[i].append(value)\n",
    "            i+=1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import fc.gate\n",
    "def auto_gate(sample, gate_fraction=.2, sigma=10):\n",
    "    '''\n",
    "    * Gates out first and last channel of all 5 channels\n",
    "    * Gates out first 250 events and last 100 events of run\n",
    "    * Performs a density gate on remaining data\n",
    "    * Transforms data to an exponential form\n",
    "    '''\n",
    "    \n",
    "    gate_fraction = float(sample.metadata['Gate Fraction']) if 'Gate Fraction' in sample.metadata and sample.metadata['Gate Fraction'] != '' else gate_fraction\n",
    "    sigma = float(sample.metadata['Sigma']) if 'Sigma' in sample.metadata and sample.metadata['Sigma'] != '' else sigma\n",
    "    trimmed_data = fc.gate.start_end(sample, num_start=250, num_end=100)\n",
    "    trimmed_data = fc.gate.high_low(trimmed_data, channels = ['FSC-H', 'SSC-H'], high=(2**10)-1, low=0)\n",
    "    gated_data, cntr = fc.gate.density2d(data = trimmed_data,\n",
    "                                        gate_fraction = gate_fraction,\n",
    "                                        sigma = sigma)\n",
    "\n",
    "    return gated_data, trimmed_data, cntr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import fc.transform\n",
    "import fc.gate\n",
    "import fc.io\n",
    "import fc.mef\n",
    "from matplotlib import pyplot\n",
    "def auto_transform(data, metadata, cached_beads, beads_dir):\n",
    "    \n",
    "    beads_file_path = metadata['Beads File Path'] if 'Beads File Path' in metadata and metadata['Beads File Path'] != '' else None\n",
    "    beads_peaks = [float(x) for x in metadata['Beads Peaks'].split(',')] if 'Beads Peaks' in metadata and metadata['Beads Peaks'] != '' else None\n",
    "    \n",
    "    #If they just include one parameter\n",
    "    if beads_file_path != None and beads_peaks == None or beads_file_path == None and beads_peaks != None:\n",
    "        raise ImportError('You must provide both the Beads File Path and the Beads Peaks (see: '+metadata['File Path']+')')\n",
    "    \n",
    "    #If beads are not provided just exponentiate\n",
    "    if beads_file_path == None and beads_peaks == None:\n",
    "        return fc.transform.exponentiate(data), None\n",
    "    \n",
    "    #If file/peaks have already been cached use them, otherwise compute new ones\n",
    "    if beads_file_path in cached_beads.keys():\n",
    "        mefl_transform = cached_beads[beads_file_path]\n",
    "    else:\n",
    "        # common gating/trimming\n",
    "        data = fc.io.TaborLabFCSData(beads_file_path)\n",
    "        trimmed_data = fc.gate.start_end(data, num_start=250, num_end=100)\n",
    "        trimmed_data = fc.gate.high_low(trimmed_data, ['FSC-H', 'SSC-H'])\n",
    "\n",
    "        # density gate\n",
    "        gated_data, cntr = fc.gate.density2d(data = trimmed_data,\n",
    "                                            gate_fraction = 0.4)\n",
    "\n",
    "        # Transform FSC/SSC\n",
    "        transf_data = fc.transform.exponentiate(trimmed_data, \n",
    "            channels = ['FSC-H', \n",
    "                        'SSC-H', \n",
    "                        ])\n",
    "        # plot\n",
    "        pyplot.figure(figsize = (6,4))\n",
    "        fc.plot.density2d(transf_data, channels = ['FSC-H', 'SSC-H'], \n",
    "            mode = 'scatter', log = True,\n",
    "            savefig = '{}/{}_density2d.png'.format(beads_dir, str(data)))\n",
    "\n",
    "\n",
    "        # mef\n",
    "        peaks_mef = numpy.array(beads_peaks)\n",
    "        mefl_transform = fc.mef.get_transform_fxn(gated_data, peaks_mef, \n",
    "            cluster_channels = ['FL1-H', 'FL2-H', 'FL3-H'],\n",
    "            mef_channels = 'FL1-H', verbose = True, plot = True,\n",
    "            plot_dir = directory)\n",
    "        cached_beads[beads_file_path] = mefl_transform\n",
    "    return fc.transform.exponentiate(data), mefl_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files...\n",
      "Generating gate for file: 1,  Number of clusters found: 6\n",
      "For channel FL1-H...\n",
      "Peaks identified:\n",
      "[  602.   654.   707.   798.   883.  1023.]\n",
      "Standard deviation:\n",
      "['19.96', '15.23', '13.24', '8.06', '7.09', '16.38']\n",
      "1 peak(s) discarded to the right.\n",
      "2 MEF value(s) discarded to the right.\n",
      "MEF values for channel FL1-H.\n",
      "[   792.   2079.   6588.  16471.  47497.]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "to_mef() takes at least 3 arguments (3 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-e0b426ea09d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m', '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_fine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_coarse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdensity2d_contour\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mauto_gate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpo_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmefl_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mauto_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeads_cache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeads_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-3f74bec11e1e>\u001b[0m in \u001b[0;36mauto_transform\u001b[1;34m(data, metadata, cached_beads, beads_dir)\u001b[0m\n\u001b[0;32m     49\u001b[0m             plot_dir = directory)\n\u001b[0;32m     50\u001b[0m         \u001b[0mcached_beads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbeads_file_path\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmefl_transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexponentiate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmefl_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: to_mef() takes at least 3 arguments (3 given)"
     ]
    }
   ],
   "source": [
    "import fc.gate, fc.transform, fc.io, os\n",
    "from Tkinter import Tk\n",
    "from tkFileDialog import askopenfilename\n",
    "\n",
    "\n",
    "\n",
    "# Import bead metadata\n",
    "# Load bead data\n",
    "# Analysis bead data\n",
    "# Graph bead data\n",
    "# Import cell metadata\n",
    "\n",
    "#Tk().withdraw() # we don't want a full GUI, so keep the root window from appearing\n",
    "#import_path = askopenfilename() # show an \"Open\" dialog box and return the path to the selected file\n",
    "import_path = \"input_form.xlsx\"\n",
    "directory = os.path.dirname(os.path.realpath(import_path))\n",
    "print \"Loading files...\"\n",
    "# Load Files\n",
    "samples = []\n",
    "for row in import_rows(import_path,\"cells\"):\n",
    "    sample = fc.io.TaborLabFCSData(row['File Path'])\n",
    "    sample.metadata = row\n",
    "    samples.append(sample)\n",
    "    \n",
    "# Generate Gates\n",
    "print \"Generating gate for file:\",\n",
    "beads_dir = directory\n",
    "beads_cache = {}\n",
    "for i, sample in enumerate(samples):\n",
    "    print str(i+1)+', ',\n",
    "    sample.data_fine, sample.data_coarse, sample.density2d_contour = auto_gate(sample)\n",
    "    sample.expo_data, sample.mefl_data = auto_transform(sample, sample.metadata, beads_cache, beads_dir)\n",
    "print ''\n",
    "    \n",
    "# Plot graphs of gating\n",
    "print \"Generating plots for file:\",\n",
    "plot_gated_folder = os.path.join(directory,'plot_gated')\n",
    "if not os.path.exists(plot_gated_folder):\n",
    "    os.makedirs(plot_gated_folder)\n",
    "for i, sample in enumerate(samples): \n",
    "    print str(i+1)+', ',\n",
    "    gate_plot(sample.data_coarse, sample.data_fine, sample.density2d_contour, title = sample.metadata['File Path'], filename = os.path.join(plot_gated_folder,'gated_%03d.png'%(i+1)))\n",
    "print ''\n",
    "\n",
    "# Generate stats\n",
    "print 'Generating stats...'\n",
    "output = generate_stats(samples)\n",
    "export_workbook(os.path.join(directory,'mefled_data.xls'),{'stats2':output})\n",
    "print 'All done!'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(fc.gate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
